{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d8f2ea",
   "metadata": {},
   "source": [
    "# Objective\n",
    " The objective is to use linear regression to find the median value of owner-occupied homes in 1000 USD's.\n",
    " We will build a Machine learning model (i.e. Linear Regression) using tensorflow.keras\n",
    " \n",
    " Data : https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Training_set_boston.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f2f33389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7d4d6482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03466</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>6.031</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>362.25</td>\n",
       "      <td>7.83</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.05042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>6.103</td>\n",
       "      <td>85.1</td>\n",
       "      <td>2.0218</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.52</td>\n",
       "      <td>23.29</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "0  15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0   \n",
       "1   0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0   \n",
       "2   0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0   \n",
       "3   7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0   \n",
       "4   0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     20.2  349.48  24.91  12.0  \n",
       "1     21.0  395.62   8.47  19.9  \n",
       "2     16.9  362.25   7.83  19.4  \n",
       "3     20.2    2.52  23.29  13.4  \n",
       "4     21.0  390.95  11.28  18.2  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Training_set_boston.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03b4f6",
   "metadata": {},
   "source": [
    "### Separating input and output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2489cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MEDV', axis = 1)\n",
    "y = df.MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1c1e70",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8a5da544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0043c330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of input features\n",
    "n_features = X.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d189a",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08853df9",
   "metadata": {},
   "source": [
    "#### 1) Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1fb7356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from numpy.random import seed\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e416de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))      \n",
    "#Note that the visible layer of the network is defined by the “input_shape” argument on the first hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0adb10",
   "metadata": {},
   "source": [
    "#### 2) Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d0058183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RMSprop optimimzer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "optimizer = RMSprop(0.01)                            # 0.01 is the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9ddf9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)       # compling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2aa51c",
   "metadata": {},
   "source": [
    "#### 3) Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c16bb182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 654.4429\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 122.2530\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 119.4115\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 80.9836\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 112.6708\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 67.1186\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 95.4212\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 69.2253\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 78.2691\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 74.8981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25cb2924b80>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value = 29\n",
    "seed(seed_value)        # If you build the model with given parameters, set_random_seed will help you produce the same result on multiple execution\n",
    "\n",
    "# Recommended by Keras -------------------------------------------------------------------------------------\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tensorflow.random.set_seed(seed_value) \n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 30, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253ed18",
   "metadata": {},
   "source": [
    "By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\n",
    "\n",
    "verbose=0 will show you nothing (silent)\n",
    "\n",
    "verbose=1 will show you an animated progress bar like this:\n",
    "\n",
    "progres_bar\n",
    "\n",
    "verbose=2 will just mention the number of epoch like this:\n",
    "\n",
    "verbose = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc72c6",
   "metadata": {},
   "source": [
    "#### 4) Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "73e66974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step - loss: 73.3094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.30943298339844"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d5a55",
   "metadata": {},
   "source": [
    "The mean squared error we got here is 116.66. Now, what does it mean?\n",
    "\n",
    "When you subtract the predicted values (of X_test data) from the acutal value (of X_test data), then square it and sum all the squares, and finally take a mean (i.e. average) of it, the result you will get is 116.66 in this case.\n",
    "\n",
    "evaluate() does this task automatically. If you want to get the prediciton for X_test you can do model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fcb89",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a983e76",
   "metadata": {},
   "source": [
    "#### 1) Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8c308df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 17710.6816\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 613.4026\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 591.8104\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 561.3018\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 524.2370\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 484.3063\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 444.6781\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 406.1779\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 369.8060\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 335.8723\n",
      "3/3 [==============================] - 0s 0s/step - loss: 280.5528\n",
      "The MSE value is: 280.5528259277344\n"
     ]
    }
   ],
   "source": [
    "# defining model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compiling model\n",
    "optimizer = RMSprop(0.1)\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "# fitting model\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 30, verbose = 1)\n",
    "\n",
    "# evaluating model\n",
    "print('The MSE value is:', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0aa2b9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 872us/step - loss: 303.8635\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 283.7628\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 267.8573\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 253.6668\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 240.3513\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 901us/step - loss: 227.5404\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 215.3663\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 203.5787\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 192.4070\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 181.9050\n",
      "3/3 [==============================] - 0s 0s/step - loss: 156.0909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156.0909423828125"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# playing with different learning rates\n",
    "learning_rate = 0.05\n",
    "epochs = 10\n",
    "optimizer = RMSprop(learning_rate)\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = epochs, batch_size = 30)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ca834",
   "metadata": {},
   "source": [
    "#### 2) Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2538b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 587.5771\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 134.0181\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 214.1360\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 170.0829\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 159.0058\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 61.9842\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 128.9540\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 81.7375\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 895us/step - loss: 97.8665\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.2344\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 73.0662\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 102.3227\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 109.2546\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 86.0036\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 76.5122\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 74.8682\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 66.2958\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 83.2599\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 54.6319\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 73.8678\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 59.5881\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 67.4139\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 59.1911\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 57.6428\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 59.3867\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 51.0639\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 63.8353\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 46.7678\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 57.2133\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 52.0722\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 51.4657\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 45.8865\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 800us/step - loss: 55.6206\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 47.0721\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 53.8397\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 42.4014\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 45.9735\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 33.1486\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 59.3277\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 44.4574\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 61.3318\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 34.8835\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 45.0748\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 41.1357\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 41.8268\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 45.8414\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 61.0375\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.9957\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 44.4909\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 40.3015\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 41.1994\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 46.1658\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.9221\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 41.6160\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 995us/step - loss: 44.5599\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 944us/step - loss: 39.8131\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 34.8730\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 43.7518\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 798us/step - loss: 34.5813\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 50.2608\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 41.4581\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 45.7097\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 900us/step - loss: 30.4073\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 36.5626\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 46.9391\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 47.4941\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 33.4984\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 38.3764\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 798us/step - loss: 49.1300\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 801us/step - loss: 37.5540\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 33.6683\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 45.3089\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 45.5621\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 900us/step - loss: 31.7806\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 42.1322\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 40.3741\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 994us/step - loss: 41.1590\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 39.6275\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 42.2709\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 798us/step - loss: 40.5977\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.8580\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 999us/step - loss: 36.0144\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 38.4253\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 26.2894\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 50.8552\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 31.3170\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 38.2215\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.0896\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 36.5338\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 43.7759\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 32.0957\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 900us/step - loss: 38.1797\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 38.5431\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 798us/step - loss: 35.5758\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 34.6576\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 865us/step - loss: 38.1115\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 32.8026\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 994us/step - loss: 43.2132\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 26.3031\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 37.1793\n",
      "3/3 [==============================] - 0s 0s/step - loss: 27.4126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.412565231323242"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.01)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 30, verbose = 1)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d7dd70ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1635.3098\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 192.2961\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 137.3567\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 119.2116\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 163.0742\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 168.5372\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 121.7346\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 98.2955\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 115.1715\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 142.5993\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 80.7931\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 107.4990\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 132.2086\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 97.9364\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 75.3715\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 87.0480\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 77.3261\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 118.9963\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 68.9710\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.1332\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 69.6296\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 87.8710\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 81.0753\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 70.1137\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 81.7445\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 68.6458\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 75.7185\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 66.4619\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 900us/step - loss: 72.2550\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 73.0910\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 57.2136\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 61.2628\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 69.9762\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 63.7751\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 62.8430\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 55.9077\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 59.1353\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 54.3657\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 67.2129\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 57.3895\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 48.9586\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 61.1093\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 55.1364\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 49.0660\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 59.1140\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 48.6081\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 67.4354\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 998us/step - loss: 41.7678\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 42.9581\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 48.2821\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 58.3802\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 52.7468\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 48.4688\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 44.7563\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 38.4704\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 60.1626\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 40.4647\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 800us/step - loss: 54.5833\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 38.9896\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 895us/step - loss: 50.0481\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 50.6990\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 894us/step - loss: 49.2465\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 40.7686\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 901us/step - loss: 46.0882\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 995us/step - loss: 43.3087\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 45.4712\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 899us/step - loss: 42.3944\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 39.8313\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 49.3507\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 40.0727\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 45.9663\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 37.2076\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 901us/step - loss: 47.0043\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 900us/step - loss: 39.6340\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 38.7456\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 42.9223\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 900us/step - loss: 40.4065\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 801us/step - loss: 43.8764\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 801us/step - loss: 45.3497\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 36.5376\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 42.0697\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 32.4266\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 801us/step - loss: 36.0499\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 43.4909\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 41.1671\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.6648\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.5549\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 36.9248\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 33.7098\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 43.6288\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 35.2914\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 897us/step - loss: 32.5452\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 900us/step - loss: 43.5383\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 33.9164\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 34.6507\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 37.2110\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 800us/step - loss: 38.3547\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1000us/step - loss: 38.4064\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 900us/step - loss: 31.4966\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 898us/step - loss: 27.5014\n",
      "3/3 [==============================] - 0s 0s/step - loss: 41.6618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.66178512573242"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with epochs and learning rate\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "optimizer = RMSprop(learning_rate)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = epochs, batch_size = 30)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f6a6e",
   "metadata": {},
   "source": [
    "#### 3) Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "76a77890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 954us/step - loss: 13990.9658\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 603.7642\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 584.9921\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 559.9788\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 531.2486\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 499.2737\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 466.4268\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 434.2851\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 402.7262\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 373.7377\n",
      "3/3 [==============================] - 0s 0s/step - loss: 315.5293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "315.5292663574219"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 40, verbose = 1)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "54647c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 354.0121\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 349.8713\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 346.7245\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 343.7578\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 340.9941\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 338.1612\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 335.3203\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 332.5108\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 329.6599\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 326.9495\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 324.1900\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 321.4869\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 318.6877\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 315.9756\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 313.2969\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 310.5357\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 307.8240\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 305.4052\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 302.8561\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 300.1338\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 297.6455\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 294.9955\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 292.5940\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 290.1034\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 287.6356\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 285.0158\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 282.6028\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 280.2471\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 277.7397\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 275.2558\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 272.9117\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 270.6035\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 268.1234\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 265.7904\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 263.2974\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 261.0355\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 258.6597\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 256.3036\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 254.0314\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 251.7126\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 249.3879\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 247.1644\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 244.9109\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 872us/step - loss: 242.7657\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 240.5615\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 238.3117\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 236.0162\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 233.9906\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 231.8356\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 229.8015\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 227.8309\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 225.6894\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 223.5421\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 221.4894\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 219.4955\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 217.4014\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 215.4097\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 873us/step - loss: 213.3694\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 211.3612\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 209.4129\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 874us/step - loss: 207.4513\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 873us/step - loss: 205.5148\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 872us/step - loss: 203.5496\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 201.7772\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 872us/step - loss: 199.9024\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 872us/step - loss: 197.8946\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 196.1806\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 194.2689\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 192.4947\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 190.6815\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 872us/step - loss: 188.8539\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 876us/step - loss: 187.0708\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 185.3224\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 183.4828\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 181.7716\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 180.1030\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 178.4256\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 176.8760\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 175.1486\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 173.4157\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 171.9151\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 998us/step - loss: 170.4569\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 169.0708\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 890us/step - loss: 167.3667\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 165.8427\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 873us/step - loss: 164.2439\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 162.6926\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 876us/step - loss: 161.1309\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 994us/step - loss: 159.7167\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 158.2688\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 994us/step - loss: 156.7426\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 155.3572\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 998us/step - loss: 153.9072\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 993us/step - loss: 152.4036\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 873us/step - loss: 151.2092\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 996us/step - loss: 149.9020\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 148.4155\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 147.1233\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 145.8342\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 144.4653\n",
      "3/3 [==============================] - 0s 0s/step - loss: 129.1917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "129.19168090820312"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# playing with batch size\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "batch_size = 40\n",
    "\n",
    "optimizer = RMSprop(learning_rate)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 1)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3087eb",
   "metadata": {},
   "source": [
    "#### Summary of Hyper-parameter tuning\n",
    "1)Training loss should steadily decrease, steeply at first, and then more slowly until the slope of the curve reaches or approaches zero.\n",
    "\n",
    "2)If the training loss does not converge, train for more epochs.\n",
    "\n",
    "3)If the training loss decreases too slowly, increase the learning rate. Note that setting the learning rate too high may also prevent training loss from converging.\n",
    "\n",
    "4)If the training loss varies wildly (that is, the training loss jumps around), decrease the learning rate.\n",
    "\n",
    "5)Lowering the learning rate while increasing the number of epochs or the batch size is often a good combination.\n",
    "\n",
    "6)Setting the batch size to a very small batch number can also cause instability. First, try large batch size values. Then, decrease the batch size until you see degradation.\n",
    "\n",
    "7)For real-world datasets consisting of a very large number of examples, the entire dataset might not fit into memory. In such cases, you'll need to reduce the batch size to enable a batch to fit into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d5b75",
   "metadata": {},
   "source": [
    "### Implementing Hyperparameter tuning using Sklearn\n",
    "\n",
    "We can automate the hyperparameter tunning using GridSearCV\n",
    "\n",
    "Implementing GridSearchCV with Sklearn using following steps:\n",
    "\n",
    "1) Define the general architecture of the model\n",
    "\n",
    "2) Define the hyperparameters grid to be validated\n",
    "\n",
    "3) Run the GridSearchCV process\n",
    "\n",
    "4) Print the results of the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1e885",
   "metadata": {},
   "source": [
    " We will integrate Sklearn and Keras properly, by (a) creating a create_model function that allows to create the model in an automated way, and (b) defining a KerasRegressor model which is an implementation of the scikit-learn regressor API for Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "39e01602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yashi\\AppData\\Local\\Temp/ipykernel_15720/3845801183.py:13: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn = create_model, verbose = 1)\n",
      "C:\\Users\\yashi\\AppData\\Local\\Temp/ipykernel_15720/3845801183.py:19: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn = create_model, verbose = 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 1ms/step - loss: 1251.5662\n",
      "Best params:{'batch_size': 10, 'nb_epoch': 100}\n"
     ]
    }
   ],
   "source": [
    "# Import GridSearchCV and Keras Regressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# 1) Define model through a user defined function\n",
    "def create_model(optimizer = RMSprop(0.01)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "    model.add(Dense(8, activation = 'relu', input_shape = (n_features,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "    return model\n",
    "model = KerasRegressor(build_fn = create_model, verbose = 1)\n",
    "\n",
    "# 2) Define the hyperparameters grid to be validated\n",
    "batch_size = [10, 20, 30, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size = batch_size, nb_epoch = epochs)\n",
    "model = KerasRegressor(build_fn = create_model, verbose = 1)\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 5, n_jobs = -1)\n",
    "\n",
    "# 3) Run GridSearchCV process\n",
    "grid_result = grid.fit(X_train, y_train, verbose = 1)\n",
    "\n",
    "# 4) Print the results of the best model\n",
    "print('Best params:' +  str(grid_result.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9b2aad95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 3ms/step - loss: 1139.0946\n",
      "2/2 [==============================] - 0s 0s/step - loss: 257.9995\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 781.8627\n",
      "2/2 [==============================] - 0s 983us/step - loss: 166.6500\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 571.3873\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 106.1974\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1278.0438\n",
      "2/2 [==============================] - 0s 0s/step - loss: 191.4823\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1108.2081\n",
      "2/2 [==============================] - 0s 0s/step - loss: 157.3527\n",
      "Results: \n",
      " * Mean: 175.93637084960938 \n",
      " * Std: 49.54020963747385\n"
     ]
    }
   ],
   "source": [
    "# import cross validation evaluator\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Measure model's performance\n",
    "results = cross_val_score(grid.best_estimator_, X_test, y_test, cv = 5)\n",
    "print('Results: \\n * Mean:', -results.mean(), '\\n * Std:', results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0eeaa",
   "metadata": {},
   "source": [
    "### Implementing Hyperparameter tuning with Keras\n",
    "We can automate hyperparameter tuning using Random Search and Keras  (prefer this over 1st method that uses sklearn)\n",
    "\n",
    "Implementing Random Search with Keras using following steps:\n",
    "\n",
    "1) Install and import all the packages needed\n",
    "\n",
    "2) Define the general architecture of the model through a creation function\n",
    "\n",
    "3) Define the hyperparameters grid to be validated\n",
    "\n",
    "4) Run the GridSearchCV process\n",
    "\n",
    "5) Print the results of the best model\n",
    "\n",
    "To execute the hyperparameter tuning procedure we will use the keras-tuner, a library that helps you pick the optimal set of hyperparameters for your TensorFlow model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "99ded967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project random_search\\untitled_project\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from random_search\\untitled_project\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# 0) Install and import all the packages needed\n",
    "\n",
    "! pip install -q -U keras-tuner\n",
    "import kerastuner as kt\n",
    "\n",
    "# 1) Define model through a user defined function\n",
    "def model_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "    model.add(Dense(8, activation = 'relu'))\n",
    "    model.add(Dense(1))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values = [1e-1, 1e-2, 1e-3, 1e-4])\n",
    "    optimizer = RMSprop(learning_rate = hp_learning_rate)\n",
    "    model.compile(loss = 'mse', metrics = ['mse'], optimizer = optimizer)\n",
    "    return model\n",
    "\n",
    "# 2) Define the hyperparameters grid to be validated\n",
    "tuner_rs = kt.RandomSearch(\n",
    "                 model_builder,                        # Takes hyperparameters (hp) and returns a Model instance\n",
    "                objective = 'mse',                     # Name of model metric to minimize or maximize\n",
    "                 seed = 29,                            # Random seed for replication purposes\n",
    "                max_trials = 5,                        # Total number of trials (model configurations) to test at most.\n",
    "                 directory = 'random_search')          # Path to the working directory (relative)  \n",
    "\n",
    "# 3) Run the GridSearchCV process\n",
    "tuner_rs.search(X_train, y_train, epochs = 10, validation_split = 0.2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7eb7b877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in random_search\\untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x0000025CBE359910>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.01\n",
      "Score: 60.36199188232422\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.001\n",
      "Score: 69.35105895996094\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.1\n",
      "Score: 113.26669311523438\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "learning_rate: 0.0001\n",
      "Score: 25066.525390625\n"
     ]
    }
   ],
   "source": [
    "tuner_rs.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "20ddf890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.momentum\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.rho\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 62.4148 - mse: 62.4148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[62.41484451293945, 62.41484451293945]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the results of the best model\n",
    "best_model = tuner_rs.get_best_models(num_models = 1)[0]\n",
    "best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b07b5234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                140       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 88        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 237\n",
      "Trainable params: 237\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223709cd",
   "metadata": {},
   "source": [
    "#### 5) Making prediction\n",
    "\n",
    "New test  Data : https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Testing_set_boston.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "88120149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "0  0.09178   0.0   4.05   0.0  0.510  6.416  84.1  2.6463   5.0  296.0   \n",
       "1  0.05644  40.0   6.41   1.0  0.447  6.758  32.9  4.0776   4.0  254.0   \n",
       "2  0.10574   0.0  27.74   0.0  0.609  5.983  98.8  1.8681   4.0  711.0   \n",
       "3  0.09164   0.0  10.81   0.0  0.413  6.065   7.8  5.2873   4.0  305.0   \n",
       "4  5.09017   0.0  18.10   0.0  0.713  6.297  91.8  2.3682  24.0  666.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     16.6  395.50   9.04  \n",
       "1     17.6  396.90   3.53  \n",
       "2     20.1  390.11  18.07  \n",
       "3     19.2  390.91   5.52  \n",
       "4     20.2  385.09  17.27  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Testing_set_boston.csv')\n",
    "new_test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e0f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(new_test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
