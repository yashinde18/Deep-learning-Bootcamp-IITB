{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51d8f2ea",
   "metadata": {},
   "source": [
    "# Objective\n",
    " The objective is to use linear regression to find the median value of owner-occupied homes in 1000 USD's.\n",
    " We will build a Machine learning model (i.e. Linear Regression) using tensorflow.keras\n",
    " \n",
    " Data : https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Training_set_boston.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2f33389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4d6482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.03466</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>6.031</td>\n",
       "      <td>23.3</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>362.25</td>\n",
       "      <td>7.83</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.05042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>6.103</td>\n",
       "      <td>85.1</td>\n",
       "      <td>2.0218</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>2.52</td>\n",
       "      <td>23.29</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN  INDUS  CHAS     NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "0  15.02340   0.0  18.10   0.0  0.6140  5.304  97.3  2.1007  24.0  666.0   \n",
       "1   0.62739   0.0   8.14   0.0  0.5380  5.834  56.5  4.4986   4.0  307.0   \n",
       "2   0.03466  35.0   6.06   0.0  0.4379  6.031  23.3  6.6407   1.0  304.0   \n",
       "3   7.05042   0.0  18.10   0.0  0.6140  6.103  85.1  2.0218  24.0  666.0   \n",
       "4   0.72580   0.0   8.14   0.0  0.5380  5.727  69.5  3.7965   4.0  307.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     20.2  349.48  24.91  12.0  \n",
       "1     21.0  395.62   8.47  19.9  \n",
       "2     16.9  362.25   7.83  19.4  \n",
       "3     20.2    2.52  23.29  13.4  \n",
       "4     21.0  390.95  11.28  18.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Training_set_boston.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03b4f6",
   "metadata": {},
   "source": [
    "### Separating input and output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2489cf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MEDV', axis = 1)\n",
    "y = df.MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1c1e70",
   "metadata": {},
   "source": [
    "### Splitting dataset into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5da544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0043c330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no of input features\n",
    "n_features = X.shape[1]\n",
    "n_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d189a",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08853df9",
   "metadata": {},
   "source": [
    "#### 1) Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fb7356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from numpy.random import seed\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e416de23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))      \n",
    "#Note that the visible layer of the network is defined by the “input_shape” argument on the first hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0adb10",
   "metadata": {},
   "source": [
    "#### 2) Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0058183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RMSprop optimimzer\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "optimizer = RMSprop(0.01)                            # 0.01 is the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ddf9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)       # compling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2aa51c",
   "metadata": {},
   "source": [
    "#### 3) Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c16bb182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 1s 3ms/step - loss: 850.7260\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 238.9503\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 200.1113\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 146.1230\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 269.7995\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 110.7625\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 218.2884\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 136.6230\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 168.5215\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 140.7047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a6cbc51f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_value = 29\n",
    "seed(seed_value)        # If you build the model with given parameters, set_random_seed will help you produce the same result on multiple execution\n",
    "\n",
    "# Recommended by Keras -------------------------------------------------------------------------------------\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "tensorflow.random.set_seed(seed_value) \n",
    "\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 30, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9253ed18",
   "metadata": {},
   "source": [
    "By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\n",
    "\n",
    "verbose=0 will show you nothing (silent)\n",
    "\n",
    "verbose=1 will show you an animated progress bar like this:\n",
    "\n",
    "progres_bar\n",
    "\n",
    "verbose=2 will just mention the number of epoch like this:\n",
    "\n",
    "verbose = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc72c6",
   "metadata": {},
   "source": [
    "#### 4) Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e66974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step - loss: 116.6633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "116.66329956054688"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785d5a55",
   "metadata": {},
   "source": [
    "The mean squared error we got here is 116.66. Now, what does it mean?\n",
    "\n",
    "When you subtract the predicted values (of X_test data) from the acutal value (of X_test data), then square it and sum all the squares, and finally take a mean (i.e. average) of it, the result you will get is 116.66 in this case.\n",
    "\n",
    "evaluate() does this task automatically. If you want to get the prediciton for X_test you can do model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fcb89",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a983e76",
   "metadata": {},
   "source": [
    "#### 1) Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c308df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 549237.5000\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 1205.2281\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 341.3297\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1116.0170\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 5351.7485\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 418.6449\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2980.2480\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 66.5329\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 79.2075\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 198.9851\n",
      "3/3 [==============================] - 0s 0s/step - loss: 144.1426\n",
      "The MSE value is: 144.14260864257812\n"
     ]
    }
   ],
   "source": [
    "# defining model\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# compiling model\n",
    "optimizer = RMSprop(0.1)\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "\n",
    "# fitting model\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 30, verbose = 1)\n",
    "\n",
    "# evaluating model\n",
    "print('The MSE value is:', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0aa2b9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.4150\n",
      "Epoch 2/10\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 85.4060\n",
      "Epoch 3/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.3506\n",
      "Epoch 4/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.3248\n",
      "Epoch 5/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.3334\n",
      "Epoch 6/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.3137\n",
      "Epoch 7/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.3816\n",
      "Epoch 8/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.3588\n",
      "Epoch 9/10\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.3342\n",
      "Epoch 10/10\n",
      "11/11 [==============================] - 0s 836us/step - loss: 85.3029\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 93.9497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "93.94967651367188"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# playing with different learning rates\n",
    "learning_rate = 0.05\n",
    "epochs = 10\n",
    "optimizer = RMSprop(learning_rate)\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = epochs, batch_size = 30)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ca834",
   "metadata": {},
   "source": [
    "#### 2) Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2538b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2917.3066\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 359.4423\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 143.9291\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 69.2657\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 92.6498\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 58.6144\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 79.3011\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 71.3325\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 65.3908\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 71.6543\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 71.8583\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 68.7715\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 73.6864\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 67.1606\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 69.8717\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 53.1284\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 64.9893\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 63.6632\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 57.5718\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 64.2588\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 57.1288\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 61.4318\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 58.8193\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 52.8742\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 58.5823\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 51.4630\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 59.0734\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 45.5711\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 58.3990\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 47.7724\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 49.4695\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 48.1396\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 54.5424\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 51.2958\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 52.0007\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 45.9340\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 46.7941\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 45.5933\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 52.4089\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 46.7068\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 997us/step - loss: 53.5393\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 40.4752\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 42.1719\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 43.8677\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 51.1823\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.7398\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 55.8714\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 32.9232\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 50.3654\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 41.7311\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 42.9960\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 47.8347\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 32.7004\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 41.3680\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 39.5142\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 43.6942\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 39.8588\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 41.7109\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 34.3932\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 50.4098\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 39.7667\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 45.7651\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 35.1126\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 45.6987\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 33.3981\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 50.9301\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 29.1583\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.8121\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 40.2102\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.2051\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.3803\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.5872\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 999us/step - loss: 53.5310\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 27.6798\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.7430\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.3465\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 41.6630\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 31.2094\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 46.2774\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 40.0466\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 29.5497\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 40.4435\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.0277\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 40.9690\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.7113\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 34.3696\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 36.0180\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 41.8026\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 35.0500\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 33.8411\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 35.5588\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 41.2033\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.0239\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 34.0048\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 34.4870\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.8613\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 33.1800\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 39.2029\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 30.3172\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 1ms/step - loss: 30.6376\n",
      "3/3 [==============================] - 0s 0s/step - loss: 23.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.871976852416992"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.01)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = 100, batch_size = 30, verbose = 1)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7dd70ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5083.3569\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 168.6192\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 943us/step - loss: 139.8480\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 141.5934\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 176.2341\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 102.5988\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 153.2032\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 126.2234\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 102.8056\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 105.3908\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 124.1387\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 108.6787\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 118.7015\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 84.1442\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 110.6859\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 82.1046\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 106.3430\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 93.2625\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 78.6993\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 105.4144\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 72.7292\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 85.5722\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 84.1372\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 91.4483\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 82.9667\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 72.0682\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 91.4797\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 80.2720\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 73.3927\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 78.4298\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 79.1425\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 72.2860\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 82.1578\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 64.4968\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 74.9555\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 68.9282\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 63.2364\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 79.9850\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 69.4291\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 69.3497\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 64.2868\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 67.5761\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 68.3025\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 55.5448\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 64.5682\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 58.3048\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 71.7849\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 47.3594\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 67.8377\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 49.8483\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 57.5546\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 57.7323\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 64.0263\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 52.2993\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 54.8667\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 59.0706\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 51.2570\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 53.0452\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 45.4598\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 52.6089\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 51.0990\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 49.5229\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 41.4585\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 39.7408\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 43.0987\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 54.2976\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 42.1719\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 42.9203\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 49.6781\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 43.7737\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 41.0021\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 43.2304\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 48.2718\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 34.8355\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 49.6349\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 42.0842\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 44.4454\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 48.7232\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 40.7444\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 45.8042\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 33.9767\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 42.3008\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 40.5557\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 47.1494\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 41.5720\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 34.9478\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 45.2943\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 40.4151\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.7408\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 43.7595\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 37.2452\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 42.0746\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 52.8612\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 37.9722\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 40.9998\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 38.5638\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 35.4935\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 47.8701\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 29.9300\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 42.5375\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 34.0110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.01097106933594"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with epochs and learning rate\n",
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "optimizer = RMSprop(learning_rate)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = epochs, batch_size = 30)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f6a6e",
   "metadata": {},
   "source": [
    "#### 3) Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76a77890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 8604.3389\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 293.3398\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 202.1410\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 177.6489\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 171.9786\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 167.6059\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 157.3383\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 267.9005\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 233.7944\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 143.4911\n",
      "3/3 [==============================] - 0s 0s/step - loss: 79.3241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.32405853271484"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (n_features,)))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "optimizer = RMSprop(0.1)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size = 40, verbose = 1)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54647c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 73.4047\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 69.0300\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 65.5986\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 73.6060\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 67.1683\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 65.1247\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 64.8872\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 65.8587\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 63.2532\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 62.1319\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 64.3863\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 66.9339\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 62.0277\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 63.7361\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 62.0371\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 60.6133\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 62.4283\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 60.4795\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 58.9594\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 62.7014\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 59.9273\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 64.9807\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 55.6068\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 55.2936\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 62.3977\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 62.9073\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 54.9005\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 58.1446\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 53.4815\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 58.1100\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 57.2412\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 53.6363\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 50.8987\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 53.8611\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 54.8865\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 51.8944\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 48.9182\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 50.4059\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 48.9901\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 55.6236\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 997us/step - loss: 52.8661\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 47.2028\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 45.8658\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 47.2200\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 48.1422\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 46.3105\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 58.1965\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 45.2538\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 44.0063\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 46.2905\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 46.1241\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 43.5173\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 44.0726\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 46.3901\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 43.7960\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 42.6646\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 42.1791\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 46.8572\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 44.3311\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 47.0337\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 39.6099\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 40.2591\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 41.3377\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 43.7515\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 42.4766\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 42.1747\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 39.2379\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 40.3477\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 40.9420\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 37.8931\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 41.0008\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 39.6154\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 40.5338\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 37.4249\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 39.6056\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 48.5206\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 40.3584\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 36.6898\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 41.1460\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 45.0045\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 40.0721\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 37.8141\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 41.0639\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 42.6227\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 42.3410\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 35.9798\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 39.2812\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 38.8574\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 37.3060\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 38.6708\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 39.3633\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 34.6723\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 46.1082\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 34.2820\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 32.5907\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 40.9890\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 33.0044\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 39.8284\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 36.8527\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 34.5664\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 27.4841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.48406982421875"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# playing with batch size\n",
    "learning_rate = 0.01\n",
    "epochs = 100\n",
    "batch_size = 40\n",
    "\n",
    "optimizer = RMSprop(learning_rate)\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "model.fit(X_train, y_train, epochs = epochs, batch_size = batch_size, verbose = 1)\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3087eb",
   "metadata": {},
   "source": [
    "#### Summary of Hyper-parameter tuning\n",
    "1)Training loss should steadily decrease, steeply at first, and then more slowly until the slope of the curve reaches or approaches zero.\n",
    "\n",
    "2)If the training loss does not converge, train for more epochs.\n",
    "\n",
    "3)If the training loss decreases too slowly, increase the learning rate. Note that setting the learning rate too high may also prevent training loss from converging.\n",
    "\n",
    "4)If the training loss varies wildly (that is, the training loss jumps around), decrease the learning rate.\n",
    "\n",
    "5)Lowering the learning rate while increasing the number of epochs or the batch size is often a good combination.\n",
    "\n",
    "6)Setting the batch size to a very small batch number can also cause instability. First, try large batch size values. Then, decrease the batch size until you see degradation.\n",
    "\n",
    "7)For real-world datasets consisting of a very large number of examples, the entire dataset might not fit into memory. In such cases, you'll need to reduce the batch size to enable a batch to fit into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223709cd",
   "metadata": {},
   "source": [
    "#### 5) Making prediction\n",
    "\n",
    "New test  Data : https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Testing_set_boston.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88120149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS   RAD    TAX  \\\n",
       "0  0.09178   0.0   4.05   0.0  0.510  6.416  84.1  2.6463   5.0  296.0   \n",
       "1  0.05644  40.0   6.41   1.0  0.447  6.758  32.9  4.0776   4.0  254.0   \n",
       "2  0.10574   0.0  27.74   0.0  0.609  5.983  98.8  1.8681   4.0  711.0   \n",
       "3  0.09164   0.0  10.81   0.0  0.413  6.065   7.8  5.2873   4.0  305.0   \n",
       "4  5.09017   0.0  18.10   0.0  0.713  6.297  91.8  2.3682  24.0  666.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     16.6  395.50   9.04  \n",
       "1     17.6  396.90   3.53  \n",
       "2     20.1  390.11  18.07  \n",
       "3     19.2  390.91   5.52  \n",
       "4     20.2  385.09  17.27  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/Boston_Housing/Testing_set_boston.csv')\n",
    "new_test_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d7901ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[28.9379   ],\n",
       "       [34.53398  ],\n",
       "       [15.273077 ],\n",
       "       [24.113585 ],\n",
       "       [18.452108 ],\n",
       "       [21.701195 ],\n",
       "       [15.855298 ],\n",
       "       [ 9.2049465],\n",
       "       [23.938395 ],\n",
       "       [20.985891 ],\n",
       "       [20.474241 ],\n",
       "       [17.770004 ],\n",
       "       [ 8.109651 ],\n",
       "       [19.706024 ],\n",
       "       [22.712486 ],\n",
       "       [23.190609 ],\n",
       "       [17.658155 ],\n",
       "       [ 8.109651 ],\n",
       "       [35.944473 ],\n",
       "       [18.174282 ],\n",
       "       [25.706903 ],\n",
       "       [27.710052 ],\n",
       "       [ 9.454191 ],\n",
       "       [25.658121 ],\n",
       "       [16.91954  ],\n",
       "       [14.770614 ],\n",
       "       [22.33461  ],\n",
       "       [ 8.109651 ],\n",
       "       [20.282507 ],\n",
       "       [20.065233 ],\n",
       "       [21.706682 ],\n",
       "       [27.340572 ],\n",
       "       [24.301758 ],\n",
       "       [26.346247 ],\n",
       "       [10.682259 ],\n",
       "       [13.731861 ],\n",
       "       [32.49585  ],\n",
       "       [23.21467  ],\n",
       "       [19.836119 ],\n",
       "       [21.010078 ],\n",
       "       [11.394365 ],\n",
       "       [31.7815   ],\n",
       "       [36.87091  ],\n",
       "       [17.534233 ],\n",
       "       [26.876036 ],\n",
       "       [18.925808 ],\n",
       "       [14.695684 ],\n",
       "       [22.570824 ],\n",
       "       [19.239208 ],\n",
       "       [32.34314  ],\n",
       "       [22.760323 ],\n",
       "       [31.200413 ],\n",
       "       [16.354702 ],\n",
       "       [28.595463 ],\n",
       "       [35.418694 ],\n",
       "       [22.711903 ],\n",
       "       [20.53982  ],\n",
       "       [33.641712 ],\n",
       "       [24.103497 ],\n",
       "       [14.118155 ],\n",
       "       [24.544106 ],\n",
       "       [31.536257 ],\n",
       "       [28.937147 ],\n",
       "       [13.577922 ],\n",
       "       [26.841108 ],\n",
       "       [13.49194  ],\n",
       "       [19.669693 ],\n",
       "       [26.799938 ],\n",
       "       [31.255882 ],\n",
       "       [ 8.109651 ],\n",
       "       [16.640772 ],\n",
       "       [28.90874  ],\n",
       "       [ 8.109651 ],\n",
       "       [25.662764 ],\n",
       "       [21.696342 ],\n",
       "       [ 8.109651 ],\n",
       "       [23.987808 ],\n",
       "       [35.787758 ],\n",
       "       [14.670053 ],\n",
       "       [ 8.109651 ],\n",
       "       [22.68021  ],\n",
       "       [ 8.109651 ],\n",
       "       [22.892372 ],\n",
       "       [ 8.109651 ],\n",
       "       [25.226763 ],\n",
       "       [28.91721  ],\n",
       "       [12.935943 ],\n",
       "       [27.458406 ],\n",
       "       [27.48607  ],\n",
       "       [21.683    ],\n",
       "       [23.505726 ],\n",
       "       [ 8.109651 ],\n",
       "       [24.222492 ],\n",
       "       [16.993914 ],\n",
       "       [26.035301 ],\n",
       "       [25.118824 ],\n",
       "       [27.39294  ],\n",
       "       [ 8.109651 ],\n",
       "       [ 8.109651 ],\n",
       "       [ 8.109651 ],\n",
       "       [19.601349 ],\n",
       "       [23.05998  ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(new_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e0f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
